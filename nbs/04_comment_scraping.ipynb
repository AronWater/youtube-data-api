{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"This library queries the YouTube API for the list of videos on any given channel and returns the video ids, details,\n",
    "and stats as a pandas dataframe that can be exported to a .csv\n",
    "\n",
    "Needs modifications for efficiency and replication\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries and load api keys\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "key_file_loc = \"C:/Users/CodeAlias/Desktop/tweepy_auth.txt\"\n",
    "\n",
    "with open(key_file_loc) as f: keys = dict(x.rstrip().split(None,1) for x in f)\n",
    "    \n",
    "key = keys['ytapi']\n",
    "\n",
    "ids = [] # or load channel ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_comments(http_endpoint, \n",
    "                 next_page_token=False, stop_after_n_iteration=1**10,\n",
    "                 cutoff_date=datetime.datetime(1990,1,1),\n",
    "                 verbose=1):\n",
    "    \n",
    "    comment_ids = []\n",
    "    reply_list = []\n",
    "    iterations = 0\n",
    "    run = True\n",
    "    while run:\n",
    "        if iterations > stop_after_n_iteration: run = False\n",
    "        \n",
    "        \n",
    "        if next_page_token:\n",
    "            http_endpoint += \"&pageToken={}\".format(next_page_token)\n",
    "\n",
    "        response = requests.get(http_endpoint)\n",
    "        response_json = load_response(response, verbose)\n",
    "        if response_json:\n",
    "            for item in response_json['items']:\n",
    "                c_id = parse_comment_metadata(item)\n",
    "                reply_list.append(c_id['comment_id'])\n",
    "                if c_id['publish_date'] <= cutoff_date: \n",
    "                    run = False\n",
    "                    break \n",
    "                if not return_date:\n",
    "                    c_id = c_id['comment_id']\n",
    "                comment_ids.append(c_id)                \n",
    "\n",
    "            try: \n",
    "                next_page_token = response_json['nextPageToken']\n",
    "                iterations += 1\n",
    "                log(\">> {} comments parsed. Next Token = {}\".format(len(commentIds), next_page_token),\n",
    "                   verbose=verbose)\n",
    "            except:\n",
    "                run = False\n",
    "        time.sleep(.1)\n",
    "        \n",
    "        return reply_list, comment_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video_comments(video_id, key, \n",
    "                       next_page_token=False,\n",
    "                       stop_after_n_iteration=1**10,\n",
    "                       cutoff_date=datetime.datetime(1990,1,1),\n",
    "                       return_date=True,\n",
    "                       verbose=1):\n",
    "    \n",
    "    if not isinstance(video_id, str):\n",
    "        raise Exception(\"Only string values permitted\")\n",
    "        \n",
    "    init_http_endpoint = (\"https://www.googleapis.com/youtube/v3/commentThreads?\"\n",
    "                         \"part=snippet&textFormat=plainText&maxResults=100&\"\n",
    "                         \"videoId={}&key={}\".format(video_id,key))\n",
    "    \n",
    "    reply_list, comment_ids = run_comments(init_http_endpoint, \n",
    "                                           next_page_token, \n",
    "                                           stop_after_n_iteration, \n",
    "                                           cutoff_date, \n",
    "                                           return_date, verbose)\n",
    "    \n",
    "    \n",
    "    for reply_id in reply_list:\n",
    "        http_endpoint = (\"https://www.googleapis.com/youtube/v3/comments?\"\n",
    "                         \"part=snippet&textFormat=plainText&maxResults=100&\"\n",
    "                         \"parentId={}&key={}\".format(reply_id,key))\n",
    "        \n",
    "        trash, replies = run_comments(http_endpoint, \n",
    "                                     next_page_token,\n",
    "                                     stop_after_n_iteration,\n",
    "                                     cutoff_date,\n",
    "                                     return_date, verbose)\n",
    "        \n",
    "        comment_ids.extend(replies)\n",
    "        \n",
    "        \n",
    "    return comment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_comment_metadata(item):\n",
    "    print(item)\n",
    "    \n",
    "    if item['snippet'].get('topLevelComment'):\n",
    "        item = item['snippet']['topLevelComment']\n",
    "        \n",
    "    comment_meta = OrderedDict(\n",
    "        \n",
    "        channel_id = item[\"snippet\"].get(\"authorChannelUrl\"),\n",
    "        channel_image_url = item[\"snippet\"].get(\"authorProfileImageUrl\"),\n",
    "        channel_display_name = item['snippet'].get('authorDisplayName'),\n",
    "        comment_id = item.get(\"id\"),\n",
    "        comment_like_count = item[\"snippet\"].get(\"likeCount\"),\n",
    "        publish_date = parse_yt_datetime(item[\"snippet\"].get(\"publishedAt\")),\n",
    "        text_display = item[\"snippet\"].get(\"textDisplay\"),\n",
    "        video_id = item[\"snippet\"].get(\"videoId\"),\n",
    "        viewer_rating = item[\"snippet\"].get(\"viewerRating\"),\n",
    "        parent_id = item[\"snippet\"].get(\"parentId\"),\n",
    "        collection_date = datetime.datetime.now() #TODO\n",
    "        \n",
    "    )\n",
    "    \n",
    "    return comment_meta\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
